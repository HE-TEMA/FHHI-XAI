{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Add the parent directory to the Python path - bad practice, but it's just for the example\n",
    "import sys\n",
    "sys.path.append(\"/home/heydari/FHHI-XAI/\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from src.glocal_analysis import run_analysis \n",
    "from src.datasets.flood_dataset import FloodDataset\n",
    "from src.datasets.DLR_dataset import DatasetDLR\n",
    "from src.plot_crp_explanations import plot_explanations, plot_one_image_explanation\n",
    "from src.minio_client import MinIOClient\n",
    "from LCRP.models import get_model \n",
    "from LCRP.utils.crp_configs import ATTRIBUTORS, CANONIZERS, VISUALIZATIONS, COMPOSITES\n",
    "\n",
    "import logging\n",
    "# Suppress specific noisy libraries if needed\n",
    "logging.getLogger(\"PIL\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"numba\").setLevel(logging.WARNING)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: ../models/flood_s_best_pidnet_modified.pt\n"
     ]
    }
   ],
   "source": [
    "# Define transformation (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "# Load dataset\n",
    "root_dir = \"../data/General_Flood_v3/\"\n",
    "dataset = FloodDataset(root_dir=root_dir, split=\"train\", transform=transform)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"pidnet\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt_path = \"../models/flood_s_best_pidnet_modified.pt\"\n",
    "\n",
    "# Loading unet with path to checkpoint\n",
    "model = get_model(model_name=\"pidnet\" , device=device ,ckpt_path = ckpt_path , classes=2)\n",
    "\n",
    "model.augment = False\n",
    "output_dir = \"../src/output/crp/pidnet_flood\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_analysis(model_name, model, dataset, output_dir=output_dir, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Without canonizer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m out_plain \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m attribution \u001b[38;5;241m=\u001b[39m ATTRIBUTORS[model_name](model)\n\u001b[1;32m     10\u001b[0m composite \u001b[38;5;241m=\u001b[39m COMPOSITES[model_name](canonizers\u001b[38;5;241m=\u001b[39m[CANONIZERS[model_name]()])\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FHHI-XAI/LCRP/models/pidnet.py:161\u001b[0m, in \u001b[0;36mPIDNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m width_output \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m    159\u001b[0m height_output \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m--> 161\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)))\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = dataset[3][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# Without canonizer\n",
    "out_plain = model(x.clone())\n",
    "\n",
    "attribution = ATTRIBUTORS[model_name](model)\n",
    "composite = COMPOSITES[model_name](canonizers=[CANONIZERS[model_name]()])\n",
    "condition = [{\"y\": 1}]\n",
    "attr = attribution(copy.deepcopy(x).requires_grad_(), condition, composite, record_layer=[\"conv1.0\"],\n",
    "                        init_rel=1)\n",
    "\n",
    "out_canon = attr.prediction\n",
    "\n",
    "print(\"Output difference:\", (out_plain - out_canon).abs().max())\n",
    "print(\"Classes:\", out_plain.argmax(), out_canon.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 480, 480])\n",
      "MEMORY STARTING: 0.03GB (max: 0.03GB)\n",
      "MEMORY AFTER FIGURE CREATION: 0.03GB (max: 0.03GB)\n",
      "MEMORY BEFORE SEGMENTATION ATTR: 0.03GB (max: 0.03GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heydari/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/cuda/memory.py:282: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during explanation: Input type (torch.cuda.FloatTensor) and bias type (torch.FloatTensor) should be the same\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and bias type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m prediction_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# if failing, try to restart the notebook and do not run analysis again, go directly to plotting\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mplot_explanations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_concepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_refimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FHHI-XAI/src/plot_crp_explanations.py:32\u001b[0m, in \u001b[0;36mplot_explanations\u001b[0;34m(model_name, model, dataset, sample_id, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Get explanation visualization\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_one_image_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_concepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_refimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Display the figure\u001b[39;00m\n\u001b[1;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(fig)\n",
      "File \u001b[0;32m~/FHHI-XAI/src/plot_crp_explanations.py:281\u001b[0m, in \u001b[0;36mplot_one_image_explanation\u001b[0;34m(model_name, model, img, dataset, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir)\u001b[0m\n\u001b[1;32m    278\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mreset_max_memory_allocated()\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Run optimized version\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_one_image_explanation_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_concepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_refimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Ensure any remaining tensors are cleared\u001b[39;00m\n\u001b[1;32m    284\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/FHHI-XAI/src/plot_crp_explanations.py:80\u001b[0m, in \u001b[0;36mplot_one_image_explanation_optimized\u001b[0;34m(model_name, model, img, dataset, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Make a copy to avoid modifying original\u001b[39;00m\n\u001b[1;32m     79\u001b[0m img_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(img)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m---> 80\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[43mattribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomposite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_rel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m log_memory(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAFTER SEGMENTATION ATTR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Get heatmap\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/crp/attribution.py:239\u001b[0m, in \u001b[0;36mCondAttribution.__call__\u001b[0;34m(self, data, conditions, composite, record_layer, mask_map, start_layer, init_rel, on_device, exclude_parallel)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mComputes conditional attributions by masking the gradient flow of PyTorch (that is replaced by zennit with relevance values).\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03mThe relevance distribution rules (as for LRP e.g.) are described in the zennit 'composite'. Relevance can be initialized at\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m        The model prediction output. If 'start_layer' is set, 'prediction' is the layer activation.       \u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exclude_parallel:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conditions_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomposite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_rel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attribute(data, conditions, composite, record_layer, mask_map, start_layer, init_rel, on_device, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/crp/attribution.py:258\u001b[0m, in \u001b[0;36mCondAttribution._conditions_wrapper\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    254\u001b[0m dist_conds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_separate_conditions(conditions)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dist_layer \u001b[38;5;129;01min\u001b[39;00m dist_conds:\n\u001b[0;32m--> 258\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_conds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdist_layer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l_name \u001b[38;5;129;01min\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mrelevances:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m l_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m relevances:\n",
      "File \u001b[0;32m~/FHHI-XAI/LCRP/utils/crp.py:79\u001b[0m, in \u001b[0;36mCondAttributionWithTiming._attribute\u001b[0;34m(self, data, conditions, composite, record_layer, mask_map, start_layer, init_rel, on_device, exclude_parallel)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     pred_start_ts \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 79\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     81\u001b[0m         pred\u001b[38;5;241m=\u001b[39mpred[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m#GALIP'S ADDITION TO MAKE THE NOTEBOOK WORK WITHOUT THINKING TOO MUCH ABOUT WHAT HE IS ACTUALLY DOING HERE\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FHHI-XAI/LCRP/models/pidnet.py:191\u001b[0m, in \u001b[0;36mPIDNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m x_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer5_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x_))\n\u001b[1;32m    189\u001b[0m x_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer5_d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x_d))\n\u001b[1;32m    190\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    192\u001b[0m     size\u001b[38;5;241m=\u001b[39m[height_output, width_output],\n\u001b[1;32m    193\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39malgc)\n\u001b[1;32m    195\u001b[0m x_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdfm(x_, x, x_d))\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FHHI-XAI/LCRP/utils/pidnet_canonizers.py:230\u001b[0m, in \u001b[0;36mPIDNetBaseCanonizer.forward_pappm\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m scale_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonizer_sum(torch\u001b[38;5;241m.\u001b[39mstack([s4, x_], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# scale_list.append(self.canonizer_sum(torch.stack([s2, x_], dim=-1)))\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m scale_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Here is some error with gradient, that dimensions do not correspond (on forward pass no problem).\u001b[39;00m\n\u001b[1;32m    233\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression(torch\u001b[38;5;241m.\u001b[39mcat([x_,scale_out],\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and bias type (torch.FloatTensor) should be the same"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1560x960 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting up main parameters\n",
    "class_id = 1\n",
    "sample_id = 0\n",
    "n_concepts = 3\n",
    "n_refimgs = 12\n",
    "layer = \"layer2.0.conv1\"\n",
    "# layer = \"layer1.1.conv1\"\n",
    "mode = \"relevance\"\n",
    "prediction_num = 0\n",
    "\n",
    "# if failing, try to restart the notebook and do not run analysis again, go directly to plotting\n",
    "plot_explanations(model_name, model, dataset, sample_id, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from crp.concepts import ChannelConcept\n",
    "from crp.helper import get_layer_names\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# === CRP & Zennit ===\n",
    "import zennit.image as zimage\n",
    "from crp.image import imgify\n",
    "from crp.concepts import ChannelConcept\n",
    "from crp.helper import get_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=8)\n",
    "# cc = ChannelConcept()\n",
    "\n",
    "# layer_names = get_layer_names(model, [torch.nn.Conv2d])\n",
    "# # Setting up CRP \n",
    "# attribution = ATTRIBUTORS[model_name](model)\n",
    "# composite = COMPOSITES[model_name](canonizers=[CANONIZERS[model_name]()])\n",
    "# condition = [{\"y\": 1}]  \n",
    "# fv = VISUALIZATIONS[model_name](attribution,\n",
    "#                                 dataset,\n",
    "#                                 layer_names,\n",
    "#                                 preprocess_fn=lambda x: x,\n",
    "#                                 path=output_dir,\n",
    "#                                 max_target=\"max\")\n",
    "\n",
    "# # Runs faster on MPS\n",
    "# device = \"mps\"\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# start = datetime.now()\n",
    "\n",
    "# activations = {}\n",
    "# attributions = {}\n",
    "# for i, (x, y) in enumerate(tqdm(dataset)):\n",
    "#     x = x.to(device).requires_grad_()\n",
    "#     condition = [{\"y\": 1}]\n",
    "#     attr = attribution(x.unsqueeze(0), condition, composite, record_layer=layer_names)\n",
    "\n",
    "#     for layer_name in layer_names:\n",
    "#         if layer_name in attr.activations.keys():\n",
    "#             if layer_name not in attributions.keys():\n",
    "#                 attributions[layer_name] = []\n",
    "#                 activations[layer_name] = []\n",
    "#             activations[layer_name].append(attr.activations[layer_name].amax((-2, -1)))\n",
    "#             attributions[layer_name].append(cc.attribute(attr.relevances[layer_name], abs_norm=True))\n",
    "\n",
    "# for layer_name in layer_names:\n",
    "#     if layer_name in attribution.keys():\n",
    "#         attributions[layer_name] = torch.cat(attributions[layer_name])\n",
    "#         activations[layer_name] = torch.cat(activations[layer_name])    \n",
    "#         folder = f\"output/pcx/pidnet_flood/{layer_name}/\"\n",
    "#         # attributions[layer_name] = torch.cat(attributions[layer_name])\n",
    "#         # activations[layer_name] = torch.cat(activations[layer_name])\n",
    "#         os.makedirs(folder, exist_ok=True)\n",
    "#         np.save(folder + \"attributions\", attributions[layer_name].cpu().numpy())\n",
    "#         np.save(folder + \"activations\", activations[layer_name].cpu().numpy())\n",
    "# end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "layer_names = get_layer_names(model, [torch.nn.Conv2d])\n",
    "layer_name = layer_names[10]\n",
    "print(layer_name)\n",
    "folder = f\"output/pcx/pidnet_flood/{layer_name}/\"\n",
    "attributions = torch.from_numpy(np.load(folder + \"attributions.npy\"))\n",
    "activations = torch.from_numpy(np.load(folder + \"activations.npy\"))\n",
    "indices = np.arange(len(dataset))\n",
    "\n",
    "num_prototypes = {\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "\n",
    "embedding_attr = UMAP(n_neighbors=5, random_state=123, n_jobs=1)\n",
    "X_attr = embedding_attr.fit_transform(attributions.detach().cpu().numpy())\n",
    "x_attr, y_attr = X_attr[:, 0], X_attr[:, 1]\n",
    "\n",
    "embedding_act = UMAP(n_neighbors=5, random_state=123, n_jobs=1)\n",
    "X_act = embedding_act.fit_transform(activations.detach().cpu().numpy())\n",
    "x_act, y_act = X_act[:, 0], X_act[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "N_PROTOTYPES = 8\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, dpi=300, figsize=(5, 3), facecolor='white')\n",
    "for i, X in enumerate([X_attr, X_act]):\n",
    "    x, y = X[:, 0], X[:, 1]\n",
    "    xmin = x.min() - 2\n",
    "    xmax = x.max() + 2\n",
    "    ymin = y.min() - 2\n",
    "    ymax = y.max() + 2\n",
    "    X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = stats.gaussian_kde(values, 0.5)\n",
    "    Z = np.reshape(kernel(positions).T, X.shape).T\n",
    "    axes[i].contour(Z, extent=[xmin, xmax, ymin, ymax], cmap=\"Greys\", alpha=0.3, extend='min', vmax=Z.max() * 1, zorder=0)\n",
    "    axes[i].scatter(x, y, s=3, alpha=0.7, zorder=1)\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_title([\"attributions\", \"activations\"][i])\n",
    "    axes[i].plot([1], y[1], 'ko', markersize=5, label=\"test image\")\n",
    "    axes[i].legend()\n",
    "\n",
    "\n",
    "prototypes = []\n",
    "gmms = []\n",
    "for i, (X, emb) in enumerate([(attributions, embedding_attr), (activations, embedding_act)]):\n",
    "    gmms.append(GaussianMixture(n_components=N_PROTOTYPES, random_state=0).fit(X.detach().cpu().numpy()))\n",
    "    prototypes.append(gmms[-1].means_)\n",
    "    mean = emb.transform(gmms[-1].means_)\n",
    "    axes[i].scatter(mean[:, 0], mean[:, 1], s=30, c=\"#1B4365\", zorder=2, label=\"prototypes\")\n",
    "    for k, prot in enumerate(mean):\n",
    "        axes[i].text(prot[0], prot[1], k, fontsize=4, color=\"white\", ha=\"center\", va=\"center\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_attr = prototypes[0]\n",
    "\n",
    "distances = np.linalg.norm(attributions[:, None, :].detach().cpu() - proto_attr, axis=2)\n",
    "prototype_samples = np.argsort(distances, axis=0)[:8]\n",
    "prototype_samples = indices[prototype_samples]\n",
    "\n",
    "fig, axs = plt.subplots(1, N_PROTOTYPES, figsize=(1*N_PROTOTYPES, 8), dpi=200, facecolor='white')\n",
    "\n",
    "\n",
    "for i in range(N_PROTOTYPES):\n",
    "    grid = make_grid(\n",
    "        [dataset[prototype_samples[j][i]][0] for j in range(8)],\n",
    "        nrow=1,\n",
    "        padding=0)\n",
    "    grid = np.array(zimage.imgify(grid.detach().cpu()))\n",
    "    img = imgify(grid)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_title(f\"{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import plot_pcx_explanations\n",
    "print(dir(plot_pcx_explanations)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot_pcx_all import plot_pcx_explanations\n",
    "plot_pcx_explanations(\"pidnet\", model.to(\"cpu\"), dataset, sample_id=100, n_concepts=5,n_refimgs=12, num_prototypes=5, layer_name=layer_name, ref_imgs_path=\"output/ref_imgs_pidnet/\", output_dir_pcx=\"output/pcx/pidnet_flood/\", output_dir_crp=\"output/crp/pidnet_flood/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[200]\n",
    "print(\"Sample shape:\", x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(1, 3, 256, 256)  # try with 3 channels first\n",
    "output = model(dummy)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tema-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
