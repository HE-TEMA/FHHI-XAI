{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:34:45.773331Z",
     "start_time": "2025-07-22T08:34:45.710165Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Add the workspace directory to the Python path so the local package is imported\n",
    "# Restart the notebook kernel after changing this to ensure the correct module is loaded\n",
    "import sys\n",
    "sys.path.append(\"/Users/heydari/Desktop/test/FHHI-XAI-PIDNET\")\n",
    "\n",
    "from src.glocal_analysis import run_analysis \n",
    "from src.datasets.flood_dataset import FloodDataset\n",
    "from src.datasets.DLR_dataset import DatasetDLR\n",
    "from src.plot_crp_explanations import plot_explanations, plot_one_image_explanation\n",
    "from src.minio_client import MinIOClient\n",
    "from LCRP.models import get_model \n",
    "from LCRP.utils.pidnet_canonizers import PIDNetCanonizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T12:42:20.634027Z",
     "start_time": "2025-07-11T12:42:20.481976Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_pidnet_model() got an unexpected keyword argument 'ckpt_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Loading pidnet with explicit checkpoint path (use existing file)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/flood_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpidnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Alternative: pass absolute path if needed\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#model = get_model(model_name=model_name, ckpt_path=\"/absolute/path/to/models/flood_model.pt\")\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model.eval()\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#model.train()\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/TEMA-FHHI-PY/FHHI-XAI/LCRP/models/__init__.py:23\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_name, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m MODELS:\n\u001b[0;32m---> 23\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: get_pidnet_model() got an unexpected keyword argument 'ckpt_path'"
     ]
    }
   ],
   "source": [
    "# Define transformation (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "# Load dataset\n",
    "root_dir = \"../data/General_Flood_v3/\"\n",
    "dataset = FloodDataset(root_dir=root_dir, split=\"train\", transform=transform)\n",
    "\n",
    "model_name = \"pidnet\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Loading pidnet with explicit checkpoint path (use existing file)\n",
    "ckpt_path = \"../models/flood_model.pt\"\n",
    "model = get_model(model_name=\"pidnet\", ckpt_path=ckpt_path)\n",
    "\n",
    "# Alternative: pass absolute path if needed\n",
    "#model = get_model(model_name=model_name, ckpt_path=\"/absolute/path/to/models/flood_model.pt\")\n",
    "# model.eval()\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.augment = False\n",
    "model.augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output/crp/pidnet_flood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_analysis(model_name, model, dataset, output_dir=output_dir, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2762975615.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    +\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from LCRP.utils.crp_configs import ATTRIBUTORS, CANONIZERS, VISUALIZATIONS, COMPOSITES\n",
    "import copy\n",
    "\n",
    "x = dataset[3][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "+\n",
    "\n",
    "# Without canonizer\n",
    "out_plain = model(x.clone())\n",
    "\n",
    "attribution = ATTRIBUTORS[model_name](model)\n",
    "composite = COMPOSITES[model_name](canonizers=[CANONIZERS[model_name]()])\n",
    "condition = [{\"y\": 1}]\n",
    "attr = attribution(copy.deepcopy(x).requires_grad_(), condition, composite, record_layer=[\"conv1.0\"],\n",
    "                        init_rel=1)\n",
    "\n",
    "out_canon = attr.prediction\n",
    "\n",
    "print(\"Output difference:\", (out_plain - out_canon).abs().max())\n",
    "print(\"Classes:\", out_plain.argmax(), out_canon.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up main parameters\n",
    "class_id = 1\n",
    "sample_id = 100\n",
    "n_concepts = 3\n",
    "n_refimgs = 12\n",
    "layer = \"layer3.1.conv1\"\n",
    "# layer = \"layer1.1.conv1\"\n",
    "mode = \"relevance\"\n",
    "prediction_num = 0\n",
    "\n",
    "# if failing, try to restart the notebook and do not run analysis again, go directly to plotting\n",
    "plot_explanations(model_name, model, dataset, sample_id, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up main parameters\n",
    "class_id = 1\n",
    "sample_id = 0\n",
    "n_concepts = 3\n",
    "n_refimgs = 12\n",
    "layer = \"layer1.1.conv1\"\n",
    "# layer = \"layer1.1.conv1\"\n",
    "mode = \"relevance\"\n",
    "prediction_num = 0\n",
    "\n",
    "# if failing, try to restart the notebook and do not run analysis again, go directly to plotting\n",
    "plot_explanations(model_name, model, dataset, sample_id, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir=output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tema-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
