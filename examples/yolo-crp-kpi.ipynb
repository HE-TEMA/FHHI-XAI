{
 "cells": [
  {
   "cell_type": "code",
   "id": "adc3e14a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4256f888",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add the parent directory to the Python path - bad practice, but it's just for the example\n",
    "import sys\n",
    "import sys\n",
    "project_root = \"/home/heydari/FHHI-XAI/\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import logging\n",
    "import re\n",
    "import pandas as pd\n",
    "from LCRP.utils.crp_configs import ATTRIBUTORS, CANONIZERS, COMPOSITES\n",
    "from src.glocal_analysis import run_analysis\n",
    "from src.plot_crp_explanations import plot_explanations\n",
    "from src.datasets.person_car_dataset import PersonCarDataset\n",
    "from LCRP.models import get_model\n",
    "import LCRP.models.yolov6 as yolov6\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "819c803c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:22:11.682987Z",
     "start_time": "2025-07-11T09:22:11.679311Z"
    }
   },
   "source": "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:22:13.121875Z",
     "start_time": "2025-07-11T09:22:13.116932Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "id": "bb05b6ad2f09d190",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ddc9013c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:22:17.709522Z",
     "start_time": "2025-07-11T09:22:17.410149Z"
    }
   },
   "source": [
    "\n",
    "dtype = torch.float32\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Resize((1280, 1280)),\n",
    "    transforms.Lambda(lambda x: x.to(dtype)), \n",
    "])\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "root_dir = \"../src/datasets/data/person_car_detection_data/Arthal/\"\n",
    "dataset = PersonCarDataset(root_dir=root_dir, split=\"train\", transform=transform)\n",
    "\n",
    "model_name = \"yolov6s6\"\n",
    "ckpt_path = \"../models/best_v6s6_ckpt.pt\"\n",
    "\n",
    "# Loading unet with path to checkpoint\n",
    "model = get_model(model_name=model_name, classes=2, ckpt_path=ckpt_path, device=device, dtype=dtype)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4f0303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloV6S6_Model(\n",
       "  (module): Model(\n",
       "    (backbone): EfficientRep6(\n",
       "      (stem): RepVGGBlock(\n",
       "        (nonlinearity): ReLU(inplace=True)\n",
       "        (se): Identity()\n",
       "        (rbr_dense): ConvModule(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (rbr_1x1): ConvModule(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (ERBlock_2): Sequential(\n",
       "        (0): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): RepBlock(\n",
       "          (conv1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (block): Sequential(\n",
       "            (0): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ERBlock_3): Sequential(\n",
       "        (0): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): RepBlock(\n",
       "          (conv1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (block): Sequential(\n",
       "            (0): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ERBlock_4): Sequential(\n",
       "        (0): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): RepBlock(\n",
       "          (conv1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (block): Sequential(\n",
       "            (0): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (3): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (4): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ERBlock_5): Sequential(\n",
       "        (0): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): RepBlock(\n",
       "          (conv1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (block): Sequential(\n",
       "            (0): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ERBlock_6): Sequential(\n",
       "        (0): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): RepBlock(\n",
       "          (conv1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (block): Sequential(\n",
       "            (0): RepVGGBlock(\n",
       "              (nonlinearity): ReLU(inplace=True)\n",
       "              (se): Identity()\n",
       "              (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (rbr_dense): ConvModule(\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (rbr_1x1): ConvModule(\n",
       "                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SimCSPSPPF(\n",
       "          (cspsppf): CSPSPPFModule(\n",
       "            (cv1): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (cv2): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (cv3): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (cv4): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "            (cv5): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (cv6): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (cv7): ConvBNReLU(\n",
       "              (block): ConvModule(\n",
       "                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): RepBiFPANNeck6(\n",
       "      (reduce_layer0): ConvBNReLU(\n",
       "        (block): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Bifusion0): BiFusion(\n",
       "        (cv1): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv2): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv3): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (upsample): Transpose(\n",
       "          (upsample_transpose): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (downsample): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (Rep_p5): RepBlock(\n",
       "        (conv1): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (reduce_layer1): ConvBNReLU(\n",
       "        (block): ConvModule(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Bifusion1): BiFusion(\n",
       "        (cv1): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv2): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv3): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (upsample): Transpose(\n",
       "          (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (downsample): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (Rep_p4): RepBlock(\n",
       "        (conv1): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (reduce_layer2): ConvBNReLU(\n",
       "        (block): ConvModule(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Bifusion2): BiFusion(\n",
       "        (cv1): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv2): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv3): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (upsample): Transpose(\n",
       "          (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (downsample): ConvBNReLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (Rep_p3): RepBlock(\n",
       "        (conv1): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample2): ConvBNReLU(\n",
       "        (block): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Rep_n4): RepBlock(\n",
       "        (conv1): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample1): ConvBNReLU(\n",
       "        (block): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Rep_n5): RepBlock(\n",
       "        (conv1): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample0): ConvBNReLU(\n",
       "        (block): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Rep_n6): RepBlock(\n",
       "        (conv1): RepVGGBlock(\n",
       "          (nonlinearity): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (rbr_dense): ConvModule(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (rbr_1x1): ConvModule(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RepVGGBlock(\n",
       "            (nonlinearity): ReLU(inplace=True)\n",
       "            (se): Identity()\n",
       "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (rbr_dense): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (rbr_1x1): ConvModule(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (detect): Detect(\n",
       "      (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (stems): ModuleList(\n",
       "        (0): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cls_convs): ModuleList(\n",
       "        (0): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (reg_convs): ModuleList(\n",
       "        (0): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ConvBNSiLU(\n",
       "          (block): ConvModule(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cls_preds): ModuleList(\n",
       "        (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (reg_preds): ModuleList(\n",
       "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(512, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "91559828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:27:37.659529Z",
     "start_time": "2025-07-11T09:27:36.644354Z"
    }
   },
   "source": [
    "\n",
    "# === Setup ===\n",
    "n_samples = 100\n",
    "dataset_size = len(dataset)  # Your dataset must be loaded here\n",
    "n_concepts = 3\n",
    "class_id = 1\n",
    "model_name = \"yolov6s6\"\n",
    "\n",
    "\n",
    "yolo_layers = [\n",
    "    \"module.backbone.stem.rbr_dense.conv\",\n",
    "    \"module.backbone.ERBlock_2.0.rbr_dense.conv\",\n",
    "    \"module.backbone.ERBlock_3.1.block.0.rbr_dense.conv\",\n",
    "    \"module.backbone.ERBlock_4.1.block.1.rbr_1x1.conv\",\n",
    "    \"module.neck.Rep_p3.conv1.rbr_1x1.conv\",\n",
    "    \"module.neck.Rep_p5.block.2.rbr_dense.conv\"\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "log_file_path = \"../examples/log_yolo_test.txt\"\n",
    "\n",
    "# === Configure Logging ===\n",
    "logging.basicConfig(filename=log_file_path, level=logging.ERROR, force=True)\n",
    "\n",
    "# === Attribution Loop ===\n",
    "sample_indices = random.sample(range(dataset_size), n_samples)\n",
    "\n",
    "for i, sample_idx in enumerate(sample_indices):\n",
    "    layer_idx = i % len(yolo_layers)\n",
    "    layer = yolo_layers[layer_idx]\n",
    "    \n",
    "    image_tensor, _ = dataset[sample_idx]\n",
    "    \n",
    "    # Log sample & layer before attribution\n",
    "    logging.error(f\"SAMPLE {sample_idx}, LAYER {layer}\")\n",
    "    \n",
    "    attribution = ATTRIBUTORS[model_name](model)\n",
    "    composite = COMPOSITES[model_name](canonizers=[CANONIZERS[model_name]()])\n",
    "    condition = [{\"y\": class_id}]\n",
    "    \n",
    "    attr = attribution(\n",
    "        copy.deepcopy(image_tensor).unsqueeze(0).requires_grad_(),\n",
    "        condition,\n",
    "        composite,\n",
    "        record_layer=[layer],\n",
    "        init_rel=1\n",
    "    )\n",
    "\n",
    "print(\"Attribution complete, logs saved.\")\n",
    "\n",
    "# === Parsing Logs & Building Tables ===\n",
    "with open(log_file_path, 'r') as f:\n",
    "    logs = f.readlines()\n",
    "\n",
    "results = []\n",
    "sample_id = None\n",
    "layer_name = None\n",
    "\n",
    "for line in logs:\n",
    "    sample_match = re.match(r'.*SAMPLE (\\d+), LAYER (.+)', line)\n",
    "    if sample_match:\n",
    "        sample_id = int(sample_match.group(1))\n",
    "        layer_name = sample_match.group(2)\n",
    "    time_match = re.search(r'Prediction time: ([\\d\\.]+), Backward time: ([\\d\\.]+), Full attribution time: ([\\d\\.]+)', line)\n",
    "    if time_match and sample_id is not None:\n",
    "        results.append({\n",
    "            \"Sample ID\": sample_id,\n",
    "            \"Layer\": layer_name,\n",
    "            \"Prediction Time (s)\": float(time_match.group(1)),\n",
    "            \"Backward Time (s)\": float(time_match.group(2)),\n",
    "            \"Full Attribution Time (s)\": float(time_match.group(3))\n",
    "        })\n",
    "        sample_id, layer_name = None, None  # Reset after match\n",
    "\n",
    "# === Save Detailed Sample Results ===\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values(by=\"Sample ID\")  # Sort for readability\n",
    "df.to_csv(\"detailed_sample_times.csv\", index=False)\n",
    "\n",
    "# === Compute & Save Global Summary Table ===\n",
    "avg_pred_time = df[\"Prediction Time (s)\"].mean()\n",
    "global_lcrp_time = df[\"Full Attribution Time (s)\"].sum()\n",
    "attr_single = df[\"Backward Time (s)\"].mean()\n",
    "allowed_time = attr_single * dataset_size\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Model Prediction (average per sample)\",\n",
    "        \"Global (LCRP) Total Time\",\n",
    "        \"Attribution Time per Sample\",\n",
    "        \"Allowed Time for Global Explanation\",\n",
    "        \"Number of Data Points\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{avg_pred_time:.4f} s\",\n",
    "        f\"{global_lcrp_time:.2f} s\",\n",
    "        f\"{attr_single:.4f} s\",\n",
    "        f\"{allowed_time:.2f} s\",\n",
    "        f\"{dataset_size}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_table.to_csv(\"KPI_explanation_summary.csv\", index=False)\n",
    "\n",
    "# === Display Output ===\n",
    "print(\"\\n==== Global Explanation Summary ====\")\n",
    "print(summary_table.to_string(index=False))\n",
    "print(\"Results saved to 'detailed_sample_times.csv' and 'KPI_explanation_summary.csv'\")\n"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 41\u001B[0m\n\u001B[1;32m     38\u001B[0m     composite \u001B[38;5;241m=\u001B[39m COMPOSITES[model_name](canonizers\u001B[38;5;241m=\u001B[39m[CANONIZERS[model_name]()])\n\u001B[1;32m     39\u001B[0m     condition \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m: class_id}]\n\u001B[0;32m---> 41\u001B[0m     attr \u001B[38;5;241m=\u001B[39m \u001B[43mattribution\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_tensor\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequires_grad_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomposite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrecord_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m        \u001B[49m\u001B[43minit_rel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttribution complete, logs saved.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# === Parsing Logs & Building Tables ===\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/crp/attribution.py:239\u001B[0m, in \u001B[0;36mCondAttribution.__call__\u001B[0;34m(self, data, conditions, composite, record_layer, mask_map, start_layer, init_rel, on_device, exclude_parallel)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;124;03mComputes conditional attributions by masking the gradient flow of PyTorch (that is replaced by zennit with relevance values).\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;124;03mThe relevance distribution rules (as for LRP e.g.) are described in the zennit 'composite'. Relevance can be initialized at\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;124;03m        The model prediction output. If 'start_layer' is set, 'prediction' is the layer activation.       \u001B[39;00m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exclude_parallel:\n\u001B[0;32m--> 239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conditions_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconditions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomposite\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecord_layer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_layer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_rel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attribute(data, conditions, composite, record_layer, mask_map, start_layer, init_rel, on_device, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/crp/attribution.py:258\u001B[0m, in \u001B[0;36mCondAttribution._conditions_wrapper\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    254\u001B[0m dist_conds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_separate_conditions(conditions)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dist_layer \u001B[38;5;129;01min\u001B[39;00m dist_conds:\n\u001B[0;32m--> 258\u001B[0m     attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attribute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdist_conds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdist_layer\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m l_name \u001B[38;5;129;01min\u001B[39;00m attr\u001B[38;5;241m.\u001B[39mrelevances:\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m l_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m relevances:\n",
      "File \u001B[0;32m~/FHHI-XAI/LCRP/utils/crp.py:79\u001B[0m, in \u001B[0;36mCondAttributionWithTiming._attribute\u001B[0;34m(self, data, conditions, composite, record_layer, mask_map, start_layer, init_rel, on_device, exclude_parallel)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     pred_start_ts \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 79\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodified\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pred, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     81\u001B[0m         pred\u001B[38;5;241m=\u001B[39mpred[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;66;03m#GALIP'S ADDITION TO MAKE THE NOTEBOOK WORK WITHOUT THINKING TOO MUCH ABOUT WHAT HE IS ACTUALLY DOING HERE\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/FHHI-XAI/LCRP/models/yolov6.py:144\u001B[0m, in \u001B[0;36mYoloV6S6_Model.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 144\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_explainable(x)\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_boxes \u001B[38;5;241m=\u001B[39m ret[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/FHHI-XAI/yolov6/models/yolo.py:35\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     34\u001B[0m     export_mode \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mis_in_onnx_export() \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport\n\u001B[0;32m---> 35\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneck(x)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m export_mode:\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/FHHI-XAI/yolov6/models/efficientrep.py:234\u001B[0m, in \u001B[0;36mEfficientRep6.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    233\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 234\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mERBlock_2(x)\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuse_P2:\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/FHHI-XAI/LCRP/utils/galip_canonizers.py:93\u001B[0m, in \u001B[0;36mYoloCanonizer.forward_\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     91\u001B[0m     id_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrbr_identity(inputs)\n\u001B[1;32m     92\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrbr_dense(inputs), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrbr_1x1(inputs), id_out]\n\u001B[0;32m---> 93\u001B[0m                 \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrbr_identity \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrbr_dense\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrbr_1x1(inputs)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     94\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcanonizer_sum(x)\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnonlinearity(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mse(x))\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/FHHI-XAI/yolov6/layers/common.py:48\u001B[0m, in \u001B[0;36mConvModule.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)))\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1857\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1854\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner()\n\u001B[1;32m   1856\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1857\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1858\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1859\u001B[0m     \u001B[38;5;66;03m# run always called hooks if they have not already been run\u001B[39;00m\n\u001B[1;32m   1860\u001B[0m     \u001B[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001B[39;00m\n\u001B[1;32m   1861\u001B[0m     \u001B[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001B[39;00m\n\u001B[1;32m   1862\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m _global_forward_hooks\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/module.py:1805\u001B[0m, in \u001B[0;36mModule._call_impl.<locals>.inner\u001B[0;34m()\u001B[0m\n\u001B[1;32m   1802\u001B[0m     bw_hook \u001B[38;5;241m=\u001B[39m BackwardHook(\u001B[38;5;28mself\u001B[39m, full_backward_hooks, backward_pre_hooks)\n\u001B[1;32m   1803\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[0;32m-> 1805\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n\u001B[1;32m   1807\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[1;32m   1808\u001B[0m         \u001B[38;5;241m*\u001B[39m_global_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[1;32m   1809\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[1;32m   1810\u001B[0m     ):\n\u001B[1;32m   1811\u001B[0m         \u001B[38;5;66;03m# mark that always called hook is run\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 554\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/TEMA-FHHI-PY/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[1;32m    539\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[1;32m    540\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    547\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[1;32m    548\u001B[0m     )\n\u001B[0;32m--> 549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5b8d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Backward Time / Prediction Time Ratio: 9.04\n",
      "Summary table updated with ratio.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the detailed sample times (produced by the main script)\n",
    "df = pd.read_csv(\"detailed_sample_times.csv\")\n",
    "\n",
    "# Calculate the Backward / Prediction Time Ratio per sample\n",
    "df[\"Backward/Prediction Ratio\"] = df[\"Backward Time (s)\"] / df[\"Prediction Time (s)\"]\n",
    "avg_ratio = df[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "print(f\"Average Backward Time / Prediction Time Ratio: {avg_ratio:.2f}\")\n",
    "\n",
    "# Load summary table to append the new metric\n",
    "summary_table = pd.read_csv(\"global_explanation_summary.csv\")\n",
    "\n",
    "# Append the ratio to the summary table\n",
    "summary_table = pd.concat([\n",
    "    summary_table,\n",
    "    pd.DataFrame({\n",
    "        \"Metric\": [\"Average Backward/Prediction Time Ratio\"],\n",
    "        \"Value\": [f\"{avg_ratio:.2f}\"]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save updated summary\n",
    "summary_table.to_csv(\"global_explanation_summary.csv\", index=False)\n",
    "\n",
    "print(\"Summary table updated with ratio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdeb7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Backward Time / Prediction Time Ratio (All Samples):\n",
      "9.04\n",
      "Layer with Minimum Average Backward/Prediction Time Ratio:\n",
      "Layer: module.backbone.ERBlock_2.0.rbr_dense.conv\n",
      "Average Ratio: 8.98\n",
      "nAll Layers' Average Ratios (sorted):\n",
      "Layer\n",
      "module.backbone.ERBlock_2.0.rbr_dense.conv    8.979345\n",
      "module.neck.Rep_p4.conv1.rbr_dense.conv       9.060862\n",
      "module.backbone.stem.rbr_dense.conv           9.067772\n",
      "Name: Backward/Prediction Ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load detailed per-sample times\n",
    "df = pd.read_csv(\"detailed_sample_times.csv\")\n",
    "\n",
    "# Calculate Backward / Prediction ratio per sample\n",
    "df[\"Backward/Prediction Ratio\"] = df[\"Backward Time (s)\"] / df[\"Prediction Time (s)\"]\n",
    "\n",
    "# Calculate overall average ratio across all samples\n",
    "avg_ratio = df[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "# Group by layer to compute average ratio per layer\n",
    "layer_avg_ratios = df.groupby(\"Layer\")[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "# Find the layer with the minimum average ratio\n",
    "min_layer = layer_avg_ratios.idxmin()\n",
    "min_ratio = layer_avg_ratios.min()\n",
    "\n",
    "# === Final Output ===\n",
    "print(\"Average Backward Time / Prediction Time Ratio (All Samples):\")\n",
    "print(f\"{avg_ratio:.2f}\")\n",
    "\n",
    "print(\"Layer with Minimum Average Backward/Prediction Time Ratio:\")\n",
    "print(f\"Layer: {min_layer}\")\n",
    "print(f\"Average Ratio: {min_ratio:.2f}\")\n",
    "\n",
    "print(\"nAll Layers' Average Ratios (sorted):\")\n",
    "print(layer_avg_ratios.sort_values())\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:29:41.330278Z",
     "start_time": "2025-07-10T12:29:41.205924Z"
    }
   },
   "cell_type": "code",
   "source": "!pkill -u heydari -f jupyter",
   "id": "59ab408878e989cf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:30:25.631694Z",
     "start_time": "2025-07-10T12:30:25.517759Z"
    }
   },
   "cell_type": "code",
   "source": "!pkill -u said -f jupyter",
   "id": "f1d72d1cc9e42ef0",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tema-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
