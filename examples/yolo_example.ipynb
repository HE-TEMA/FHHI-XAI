{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T15:23:53.307150Z",
     "start_time": "2025-07-22T15:23:53.203830Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /path/to/your/venv/bin/activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T15:42:07.725240Z",
     "start_time": "2025-07-22T15:42:06.978083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "    # move data to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T14:46:39.606118Z",
     "start_time": "2025-07-22T14:46:39.589945Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "project_root = \"/Users/heydari/Documents/TEMA-FHHI-PY/FHHI-XAI/\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T14:47:18.483404Z",
     "start_time": "2025-07-22T14:47:16.952135Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add the parent directory to the Python path - bad practice, but it's just for the example\n",
    "import sys\n",
    "\n",
    "import sys\n",
    "project_root = \"/home/heydari/FHHI-XAI/\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "#import sys\n",
    "#sys.path.append(\"/Users/heydari/Documents/TEMA-FHHI-PY/FHHI-XAI/\")\n",
    "\n",
    "from src.glocal_analysis import run_analysis\n",
    "from src.plot_crp_explanations import plot_explanations\n",
    "from src.datasets.person_car_dataset import PersonCarDataset\n",
    "from LCRP.models import get_model\n",
    "import LCRP.models.yolov6 as yolov6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T15:28:05.347101Z",
     "start_time": "2025-07-22T15:28:05.317269Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T15:28:09.383114Z",
     "start_time": "2025-07-22T15:28:09.352950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Resize((1280, 1280)),\n",
    "    transforms.Lambda(lambda x: x.to(dtype)), \n",
    "])\n",
    "import sys\n",
    "project_root = \"/home/heydari/FHHI-XAI/\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "root_dir = \"/home/heydari/FHHI-XAI/src/datasets/data/person_car_detection_data/Arthal/\"\n",
    "dataset = PersonCarDataset(root_dir=root_dir, split=\"train\", transform=transform)\n",
    "\n",
    "model_name = \"yolov6s6\"\n",
    "ckpt_path = \"/home/heydari/FHHI-XAI/src/models/best_v6s6_ckpt.pt\"\n",
    "\n",
    "# Loading unet with path to checkpoint\n",
    "model = get_model(model_name=model_name, classes=2, ckpt_path=ckpt_path, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(100):\n",
    "    img, label = dataset[idx]  # Load image and label from dataset\n",
    "    img = img.unsqueeze(0).to(device)  # Add batch dimension and move to GPU\n",
    "\n",
    "    scores, boxes = model.predict_with_boxes(img)  # Run inference\n",
    "\n",
    "    num_boxes = boxes.shape[0] if boxes is not None else 0  # Safe check\n",
    "\n",
    "    print(f\"Image {idx} â†’ Detected {num_boxes} boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.argmax(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running analysis and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This folder contains results of the glocal analysis.\n",
    "\n",
    "output_dir = \"../output/crp/yolo_person_car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if needed, takes a long time (79 on cpu on my laptop).\n",
    "# run_analysis(model_name, model, dataset, output_dir=\"output/crp/yolo_person_car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Setup ===\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "n_samples = 100\n",
    "dataset_size = len(dataset)\n",
    "n_concepts = 3\n",
    "class_id = 1\n",
    "model_name = \"yolov6s6\"\n",
    "\n",
    "yolo_layers = [\n",
    "    \"module.backbone.stem.rbr_dense.conv\",\n",
    "    \"module.backbone.ERBlock_2.0.rbr_dense.conv\",\n",
    "    \"module.backbone.ERBlock_3.1.block.0.rbr_dense.conv\",\n",
    "    \"module.backbone.ERBlock_4.1.block.1.rbr_1x1.conv\",\n",
    "    \"module.neck.Rep_p3.conv1.rbr_1x1.conv\",\n",
    "    \"module.neck.Rep_p5.block.2.rbr_dense.conv\"\n",
    "]\n",
    "\n",
    "log_file_path = \"../examples/log_yolo_test.txt\"\n",
    "\n",
    "# === Configure Logging ===\n",
    "logging.basicConfig(filename=log_file_path, level=logging.ERROR, force=True)\n",
    "\n",
    "# === Attribution Loop ===\n",
    "sample_indices = random.sample(range(dataset_size), n_samples)\n",
    "\n",
    "for i, sample_idx in enumerate(sample_indices):\n",
    "    layer_idx = i % len(yolo_layers)\n",
    "    layer = yolo_layers[layer_idx]\n",
    "\n",
    "    image_tensor, _ = dataset[sample_idx]\n",
    "    image_tensor = image_tensor.to(device)  #  Move to same device as model\n",
    "\n",
    "    # Log sample & layer before attribution\n",
    "    logging.error(f\"SAMPLE {sample_idx}, LAYER {layer}\")\n",
    "\n",
    "    attribution = ATTRIBUTORS[model_name](model)\n",
    "    composite = COMPOSITES[model_name](canonizers=[CANONIZERS[model_name]()])\n",
    "    condition = [{\"y\": class_id}]\n",
    "\n",
    "    input_tensor = copy.deepcopy(image_tensor).unsqueeze(0).requires_grad_()\n",
    "\n",
    "    #  Ensure input_tensor is on correct device (defensive check)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    attr = attribution(\n",
    "        input_tensor,\n",
    "        condition,\n",
    "        composite,\n",
    "        record_layer=[layer],\n",
    "        init_rel=1\n",
    "    )\n",
    "\n",
    "print(\"Attribution complete, logs saved.\")\n",
    "\n",
    "# === Parsing Logs & Building Tables ===\n",
    "with open(log_file_path, 'r') as f:\n",
    "    logs = f.readlines()\n",
    "\n",
    "results = []\n",
    "sample_id = None\n",
    "layer_name = None\n",
    "\n",
    "for line in logs:\n",
    "    sample_match = re.match(r'.*SAMPLE (\\d+), LAYER (.+)', line)\n",
    "    if sample_match:\n",
    "        sample_id = int(sample_match.group(1))\n",
    "        layer_name = sample_match.group(2)\n",
    "    time_match = re.search(r'Prediction time: ([\\d\\.]+), Backward time: ([\\d\\.]+), Full attribution time: ([\\d\\.]+)', line)\n",
    "    if time_match and sample_id is not None:\n",
    "        results.append({\n",
    "            \"Sample ID\": sample_id,\n",
    "            \"Layer\": layer_name,\n",
    "            \"Prediction Time (s)\": float(time_match.group(1)),\n",
    "            \"Backward Time (s)\": float(time_match.group(2)),\n",
    "            \"Full Attribution Time (s)\": float(time_match.group(3))\n",
    "        })\n",
    "        sample_id, layer_name = None, None\n",
    "\n",
    "# === Save Detailed Sample Results ===\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values(by=\"Sample ID\")\n",
    "df.to_csv(\"detailed_sample_times.csv\", index=False)\n",
    "\n",
    "# === Compute & Save Global Summary Table ===\n",
    "avg_pred_time = df[\"Prediction Time (s)\"].mean()\n",
    "global_lcrp_time = df[\"Full Attribution Time (s)\"].sum()\n",
    "attr_single = df[\"Backward Time (s)\"].mean()\n",
    "allowed_time = attr_single * dataset_size\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Model Prediction (average per sample)\",\n",
    "        \"Global (LCRP) Total Time\",\n",
    "        \"Attribution Time per Sample\",\n",
    "        \"Allowed Time for Global Explanation\",\n",
    "        \"Number of Data Points\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{avg_pred_time:.4f} s\",\n",
    "        f\"{global_lcrp_time:.2f} s\",\n",
    "        f\"{attr_single:.4f} s\",\n",
    "        f\"{allowed_time:.2f} s\",\n",
    "        f\"{dataset_size}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_table.to_csv(\"KPI_explanation_summary.csv\", index=False)\n",
    "\n",
    "# === Display Output ===\n",
    "print(\"\\n==== Global Explanation Summary ====\")\n",
    "print(summary_table.to_string(index=False))\n",
    "print(\"Results saved to 'detailed_sample_times.csv' and 'KPI_explanation_summary.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the detailed sample times (produced by the main script)\n",
    "df = pd.read_csv(\"detailed_sample_times.csv\")\n",
    "\n",
    "# Calculate the Backward / Prediction Time Ratio per sample\n",
    "df[\"Backward/Prediction Ratio\"] = df[\"Backward Time (s)\"] / df[\"Prediction Time (s)\"]\n",
    "avg_ratio = df[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "print(f\"Average Backward Time / Prediction Time Ratio: {avg_ratio:.2f}\")\n",
    "\n",
    "# Load summary table to append the new metric\n",
    "summary_table = pd.read_csv(\"global_explanation_summary.csv\")\n",
    "\n",
    "# Append the ratio to the summary table\n",
    "summary_table = pd.concat([\n",
    "    summary_table,\n",
    "    pd.DataFrame({\n",
    "        \"Metric\": [\"Average Backward/Prediction Time Ratio\"],\n",
    "        \"Value\": [f\"{avg_ratio:.2f}\"]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save updated summary\n",
    "summary_table.to_csv(\"global_explanation_summary.csv\", index=False)\n",
    "\n",
    "print(\"Summary table updated with ratio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detailed per-sample times\n",
    "df = pd.read_csv(\"detailed_sample_times.csv\")\n",
    "\n",
    "# Calculate Backward / Prediction ratio per sample\n",
    "df[\"Backward/Prediction Ratio\"] = df[\"Backward Time (s)\"] / df[\"Prediction Time (s)\"]\n",
    "\n",
    "# Calculate overall average ratio across all samples\n",
    "avg_ratio = df[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "# Group by layer to compute average ratio per layer\n",
    "layer_avg_ratios = df.groupby(\"Layer\")[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "# Find the layer with the minimum average ratio\n",
    "min_layer = layer_avg_ratios.idxmin()\n",
    "min_ratio = layer_avg_ratios.min()\n",
    "\n",
    "# === Final Output ===\n",
    "print(\"Average Backward Time / Prediction Time Ratio (All Samples):\")\n",
    "print(f\"{avg_ratio:.2f}\")\n",
    "\n",
    "print(\"Layer with Minimum Average Backward/Prediction Time Ratio:\")\n",
    "print(f\"Layer: {min_layer}\")\n",
    "print(f\"Average Ratio: {min_ratio:.2f}\")\n",
    "\n",
    "print(\"nAll Layers' Average Ratios (sorted):\")\n",
    "print(layer_avg_ratios.sort_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up main parameters\n",
    "class_id = 1 #1/2\n",
    "sample_id = 11 #data number in the dataset\n",
    "n_concepts =  3#jj\n",
    "n_refimgs = 12 # constant\n",
    "layer = \"module.backbone.ERBlock_4.1.block.1.rbr_1x1.conv\" # change the layer\n",
    "mode = \"relevance\"\n",
    "prediction_num = 0 \n",
    "\n",
    "# if failing, try to restart the notebook and do not run analysis again, go directly to plotting\n",
    "plot_explanations(model_name, model, dataset, sample_id, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Setup ===\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "n_samples = 100\n",
    "dataset_size = len(dataset)\n",
    "n_concepts = 3\n",
    "class_id = 1\n",
    "model_name = \"yolov6s6\"\n",
    "\n",
    "yolo_layers = [\n",
    "    \"module.backbone.ERBlock_4.1.block.1.rbr_1x1.conv\",\n",
    "]\n",
    "\n",
    "log_file_path = \"../examples/log_yolo_test_4.1.txt\"\n",
    "\n",
    "# === Configure Logging ===\n",
    "logging.basicConfig(filename=log_file_path, level=logging.ERROR, force=True)\n",
    "\n",
    "# === Attribution Loop ===\n",
    "sample_indices = random.sample(range(dataset_size), n_samples)\n",
    "\n",
    "for i, sample_idx in enumerate(sample_indices):\n",
    "    layer_idx = i % len(yolo_layers)\n",
    "    layer = yolo_layers[layer_idx]\n",
    "\n",
    "    image_tensor, _ = dataset[sample_idx]\n",
    "    image_tensor = image_tensor.to(device)  #  Move to same device as model\n",
    "\n",
    "    # Log sample & layer before attribution\n",
    "    logging.error(f\"SAMPLE {sample_idx}, LAYER {layer}\")\n",
    "\n",
    "    attribution = ATTRIBUTORS[model_name](model)\n",
    "    composite = COMPOSITES[model_name](canonizers=[CANONIZERS[model_name]()])\n",
    "    condition = [{\"y\": class_id}]\n",
    "\n",
    "    input_tensor = copy.deepcopy(image_tensor).unsqueeze(0).requires_grad_()\n",
    "\n",
    "    #  Ensure input_tensor is on correct device (defensive check)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    attr = attribution(\n",
    "        input_tensor,\n",
    "        condition,\n",
    "        composite,\n",
    "        record_layer=[layer],\n",
    "        init_rel=1\n",
    "    )\n",
    "\n",
    "print(\"Attribution complete, logs saved.\")\n",
    "\n",
    "# === Parsing Logs & Building Tables ===\n",
    "with open(log_file_path, 'r') as f:\n",
    "    logs = f.readlines()\n",
    "\n",
    "results = []\n",
    "sample_id = None\n",
    "layer_name = None\n",
    "\n",
    "for line in logs:\n",
    "    sample_match = re.match(r'.*SAMPLE (\\d+), LAYER (.+)', line)\n",
    "    if sample_match:\n",
    "        sample_id = int(sample_match.group(1))\n",
    "        layer_name = sample_match.group(2)\n",
    "    time_match = re.search(r'Prediction time: ([\\d\\.]+), Backward time: ([\\d\\.]+), Full attribution time: ([\\d\\.]+)', line)\n",
    "    if time_match and sample_id is not None:\n",
    "        results.append({\n",
    "            \"Sample ID\": sample_id,\n",
    "            \"Layer\": layer_name,\n",
    "            \"Prediction Time (s)\": float(time_match.group(1)),\n",
    "            \"Backward Time (s)\": float(time_match.group(2)),\n",
    "            \"Full Attribution Time (s)\": float(time_match.group(3))\n",
    "        })\n",
    "        sample_id, layer_name = None, None\n",
    "\n",
    "# === Save Detailed Sample Results ===\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values(by=\"Sample ID\")\n",
    "df.to_csv(\"detailed_sample_times_4.1.csv\", index=False)\n",
    "\n",
    "# === Compute & Save Global Summary Table ===\n",
    "avg_pred_time = df[\"Prediction Time (s)\"].mean()\n",
    "global_lcrp_time = df[\"Full Attribution Time (s)\"].sum()\n",
    "attr_single = df[\"Backward Time (s)\"].mean()\n",
    "allowed_time = attr_single * dataset_size\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Model Prediction (average per sample)\",\n",
    "        \"Global (LCRP) Total Time\",\n",
    "        \"Attribution Time per Sample\",\n",
    "        \"Allowed Time for Global Explanation\",\n",
    "        \"Number of Data Points\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{avg_pred_time:.4f} s\",\n",
    "        f\"{global_lcrp_time:.2f} s\",\n",
    "        f\"{attr_single:.4f} s\",\n",
    "        f\"{allowed_time:.2f} s\",\n",
    "        f\"{dataset_size}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_table.to_csv(\"KPI_explanation_summary_4.1.csv\", index=False)\n",
    "\n",
    "# === Display Output ===\n",
    "print(\"\\n==== Global Explanation Summary ====\")\n",
    "print(summary_table.to_string(index=False))\n",
    "print(\"Results saved to 'detailed_sample_times.csv' and 'KPI_explanation_summary_4.1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the detailed sample times (produced by the main script)\n",
    "df = pd.read_csv(\"detailed_sample_times_4.1.csv\")\n",
    "\n",
    "# Calculate the Backward / Prediction Time Ratio per sample\n",
    "df[\"Backward/Prediction Ratio\"] = df[\"Backward Time (s)\"] / df[\"Prediction Time (s)\"]\n",
    "avg_ratio = df[\"Backward/Prediction Ratio\"].mean()\n",
    "\n",
    "print(f\"Average Backward Time / Prediction Time Ratio: {avg_ratio:.2f}\")\n",
    "\n",
    "# Load summary table to append the new metric\n",
    "summary_table = pd.read_csv(\"global_explanation_summary.csv\")\n",
    "\n",
    "# Append the ratio to the summary table\n",
    "summary_table = pd.concat([\n",
    "    summary_table,\n",
    "    pd.DataFrame({\n",
    "        \"Metric\": [\"4_1 Average Backward/Prediction Time Ratio\"],\n",
    "        \"Value\": [f\"{avg_ratio:.2f}\"]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save updated summary\n",
    "summary_table.to_csv(\"global_explanation_summary_4.1.csv\", index=False)\n",
    "\n",
    "print(\"Summary table updated with ratio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:42:46.270246Z",
     "start_time": "2025-07-22T08:42:46.100154Z"
    }
   },
   "outputs": [],
   "source": [
    "!pkill -u heydari -f jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
