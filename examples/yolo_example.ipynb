{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add the parent directory to the Python path - bad practice, but it's just for the example\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "\n",
    "from src.glocal_analysis import run_analysis \n",
    "from src.plot_crp_explanations import plot_explanations\n",
    "from src.datasets.person_car_dataset import PersonCarDataset\n",
    "from LCRP.models import get_model \n",
    "import LCRP.models.yolov6 as yolov6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Resize((1280, 1280)),\n",
    "    transforms.Lambda(lambda x: x.to(dtype)), \n",
    "])\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "root_dir = \"../data/person_car_detection_data/Arthal/\"\n",
    "dataset = PersonCarDataset(root_dir=root_dir, split=\"train\", transform=transform)\n",
    "\n",
    "model_name = \"yolov6s6\"\n",
    "ckpt_path = \"../models/best_v6s6_ckpt.pt\"\n",
    "\n",
    "# Loading unet with path to checkpoint\n",
    "model = get_model(model_name=model_name, classes=2, ckpt_path=ckpt_path, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running analysis and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This folder contains results of the glocal analysis.\n",
    "\n",
    "output_dir = \"../output/crp/yolo_person_car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if needed, takes a long time (79 on cpu on my laptop).\n",
    "# run_analysis(model_name, model, dataset, output_dir=\"output/crp/yolo_person_car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 8])\n",
      "torch.Size([9, 8])\n",
      "Predicted classes:  [1]\n",
      "Concepts: torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0147, 0.0145]),\n",
      "indices=tensor([185, 418, 499]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kortukov/git/FHHI-XAI/examples/../src/plot_crp_explanations.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes = torch.tensor(predicted_boxes, dtype=torch.float)[None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 8])\n"
     ]
    }
   ],
   "source": [
    "# Setting up main parameters\n",
    "class_id = 1\n",
    "sample_id = 11\n",
    "n_concepts = 3\n",
    "n_refimgs = 12\n",
    "layer = \"module.backbone.ERBlock_6.2.cspsppf.cv7.block.conv\"\n",
    "mode = \"relevance\"\n",
    "prediction_num = 0\n",
    "\n",
    "# if failing, try to restart the notebook and do not run analysis again, go directly to plotting\n",
    "plot_explanations(model_name, model, dataset, sample_id, class_id, layer, prediction_num, mode, n_concepts, n_refimgs, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tema",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
